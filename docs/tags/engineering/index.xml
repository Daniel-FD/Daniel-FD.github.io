<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Engineering on Daniel Fiuza Dosil</title><link>https://daniel-fd.github.io/tags/engineering/</link><description>Recent content in Engineering on Daniel Fiuza Dosil</description><generator>Hugo</generator><language>en-gb</language><lastBuildDate>Sun, 15 Dec 2024 10:00:00 +0000</lastBuildDate><atom:link href="https://daniel-fd.github.io/tags/engineering/index.xml" rel="self" type="application/rss+xml"/><item><title>Building Production LLM Systems: Lessons from the Field</title><link>https://daniel-fd.github.io/blog/building-production-llm-systems/</link><pubDate>Sun, 15 Dec 2024 10:00:00 +0000</pubDate><guid>https://daniel-fd.github.io/blog/building-production-llm-systems/</guid><description>&lt;p>After spending over two years building and deploying LLM-powered applications at scale, I&amp;rsquo;ve learned that production AI systems require a fundamentally different approach than research prototypes.&lt;/p>
&lt;h2 id="the-reality-check">The Reality Check&lt;/h2>
&lt;p>When we first started building our customer vulnerability prediction system at HelpFirst, I thought the hardest part would be achieving good accuracy. I was wrong.&lt;/p>
&lt;p>The real challenges came after we had a working model:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Latency requirements&lt;/strong>: Users expect sub-second responses&lt;/li>
&lt;li>&lt;strong>Cost control&lt;/strong>: LLM API costs can spiral quickly at scale&lt;/li>
&lt;li>&lt;strong>Reliability&lt;/strong>: 99.9% uptime isn&amp;rsquo;t negotiable for production systems&lt;/li>
&lt;li>&lt;strong>Interpretability&lt;/strong>: Stakeholders need to understand model decisions&lt;/li>
&lt;/ul>
&lt;h2 id="key-lessons-learned">Key Lessons Learned&lt;/h2>
&lt;h3 id="1-start-with-the-simplest-solution">1. Start with the Simplest Solution&lt;/h3>
&lt;p>Our first prototype used GPT-4 for everything. It worked great in demos but was too slow and expensive for production. We ended up with a hybrid approach:&lt;/p></description></item></channel></rss>